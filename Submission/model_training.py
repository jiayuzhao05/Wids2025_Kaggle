# -*- coding: utf-8 -*-
"""Wids_ZJY.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F6LjGRnUT5-G48nIQqJs3fVRh5T3_Ym5
"""

!pip install torch_geometric

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.multioutput import MultiOutputClassifier
from sklearn.decomposition import PCA
from sklearn.feature_selection import VarianceThreshold
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool
from torch_geometric.data import DataLoader
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GINConv, global_add_pool
import torch.nn.functional as F
from torch.nn import Linear, Sequential, ReLU

categorical_df = pd.read_excel("TRAIN_CATEGORICAL_METADATA_new.xlsx")
quantitative_df = pd.read_excel("TRAIN_QUANTITATIVE_METADATA_new.xlsx")
solutions_df = pd.read_excel("TRAINING_SOLUTIONS.xlsx")
connectome_df = pd.read_csv("TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv")

# 合并分类表 + 数值表 + 解决方案标签表
merged_df = solutions_df.merge(categorical_df, on="participant_id", how="left")
merged_df = merged_df.merge(quantitative_df, on="participant_id", how="left")

# 缺失值
missing_percent = merged_df.isnull().mean()
columns_to_drop = missing_percent[missing_percent > 0.3].index.tolist()
merged_df_cleaned = merged_df.drop(columns=columns_to_drop)

print(merged_df_cleaned.columns.tolist())

# ADHD & Gender 分布
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
sns.countplot(data=merged_df_cleaned, x="ADHD_Outcome", palette="Set2")
plt.title("Distribution of ADHD diagnoses")

plt.subplot(1, 2, 2)
sns.countplot(data=merged_df_cleaned, x="Sex_F", palette="Set3")
plt.title("Sex distribution")

plt.tight_layout()
plt.show()

# 仅保留数值列
numeric_cols = merged_df_cleaned.select_dtypes(include="number")

# 相关性矩阵
corr_matrix = numeric_cols.corr()

plt.figure(figsize=(14, 12))
sns.heatmap(corr_matrix, cmap='coolwarm', center=0, annot=False, fmt=".2f", linewidths=0.5)
plt.title("Correlation heat map between numeric variables", fontsize=16)
plt.show()

full_connectome = connectome_df.merge(
    merged_df_cleaned[["participant_id", "ADHD_Outcome", "Sex_F"]],
    on="participant_id"
)

from scipy.stats import ttest_ind

# 获取连接矩阵的列名（排除 meta 信息）
connection_cols = [col for col in full_connectome.columns if col not in ["participant_id", "ADHD_Outcome", "Sex_F"]]

# ADHD 组 vs 非ADHD 组对比
adhd_group = full_connectome[full_connectome["ADHD_Outcome"] == 1]
non_adhd_group = full_connectome[full_connectome["ADHD_Outcome"] == 0]

significant_connections = []

for col in connection_cols:
    t_stat, p_val = ttest_ind(adhd_group[col], non_adhd_group[col], equal_var=False)
    if p_val < 0.05:
        significant_connections.append((col, p_val))

# 显示有统计学显著的连接数量
print(f"The number of connections significantly associated with ADHD: {len(significant_connections)}")
# 按 p 值排序输出前10个
significant_connections[:10]

# 数值型列：中位数填补
for col in merged_df_cleaned.select_dtypes(include='number').columns:
    merged_df_cleaned[col] = merged_df_cleaned[col].fillna(merged_df_cleaned[col].median())

# 对象型列：众数填补
for col in merged_df_cleaned.select_dtypes(include='object').columns:
    if col != 'participant_id':
        merged_df_cleaned[col] = merged_df_cleaned[col].fillna(merged_df_cleaned[col].mode()[0])

# 合并功能性连接矩阵
full_df = merged_df_cleaned.merge(connectome_df, on="participant_id", how="left")

# 填补连接矩阵中的缺失值
for col in connectome_df.columns:
    if col != 'participant_id':
        full_df[col] = full_df[col].fillna(full_df[col].median())

# 分离标签与特征
y = full_df[['ADHD_Outcome', 'Sex_F']]
X = full_df.drop(columns=['participant_id', 'ADHD_Outcome', 'Sex_F'])

# 标准化所有特征
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# 组合最终数据集
final_df = pd.concat([X_scaled, y.reset_index(drop=True)], axis=1)

print(final_df.head())

"""提取并展示前10个重要主成分的详细结果"""

# Fill missing values
for col in merged_df_cleaned.select_dtypes(include='number').columns:
    merged_df_cleaned[col] = merged_df_cleaned[col].fillna(merged_df_cleaned[col].median())
for col in merged_df_cleaned.select_dtypes(include='object').columns:
    if col != 'participant_id':
        merged_df_cleaned[col] = merged_df_cleaned[col].fillna(merged_df_cleaned[col].mode()[0])

# Merge with connectome
full_df = merged_df_cleaned.merge(connectome_df, on="participant_id", how="left")
for col in connectome_df.columns:
    if col != 'participant_id':
        full_df[col] = full_df[col].fillna(full_df[col].median())

# Extract features and targets
y = full_df[['ADHD_Outcome', 'Sex_F']]
X = full_df.drop(columns=['participant_id', 'ADHD_Outcome', 'Sex_F'])

# Standardize features
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Dimensionality Reduction using Variance Threshold + PCA
var_thresh = VarianceThreshold(threshold=0.01)
X_reduced = var_thresh.fit_transform(X_scaled)

pca = PCA(n_components=50, random_state=42)
X_pca = pca.fit_transform(X_reduced)

pca_columns = [f'PC{i+1}' for i in range(X_pca.shape[1])]
X_pca_df = pd.DataFrame(X_pca, columns=pca_columns)

# Train models
rf_model = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))
xgb_model = MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))
lasso_model = MultiOutputClassifier(LogisticRegression(penalty='l1', solver='saga', C=0.1, max_iter=10000, random_state=42))

rf_model.fit(X_pca_df, y)
xgb_model.fit(X_pca_df, y)
lasso_model.fit(X_pca_df, y)

import numpy as np
import matplotlib.pyplot as plt

# XGBoost
# 提取子模型（用于ADHD和性别预测）
adhd_model = xgb_model.estimators_[0]
gender_model = xgb_model.estimators_[1]

# 特征重要性
adhd_importance = adhd_model.feature_importances_
gender_importance = gender_model.feature_importances_

indices = np.argsort(adhd_importance)[-10:]  # Top 10
feature_names = X_pca_df.columns[indices]

plt.figure(figsize=(10, 6))
plt.barh(feature_names, adhd_importance[indices], color='skyblue')
plt.xlabel("Feature Importance")
plt.title("Top 10 Features - ADHD Prediction (XGBoost)")
plt.grid(True)
plt.tight_layout()
plt.show()

from sklearn.metrics import accuracy_score

# 多输出预测
y_pred = xgb_model.predict(X_pca_df)

print("ADHD 预测准确率：", accuracy_score(y.iloc[:, 0], y_pred[:, 0]))
print("性别 预测准确率：", accuracy_score(y.iloc[:, 1], y_pred[:, 1]))

# Collect importances
rf_importance = rf_model.estimators_[0].feature_importances_
xgb_importance = xgb_model.estimators_[0].feature_importances_
lasso_coeff = lasso_model.estimators_[0].coef_[0]

# Assemble results
feature_importance_pca_df = pd.DataFrame({
    'PCA_Component': X_pca_df.columns,
    'RandomForest_Importance': rf_importance,
    'XGBoost_Importance': xgb_importance,
    'LASSO_Coefficient': lasso_coeff
}).sort_values(by='RandomForest_Importance', ascending=False)

!pip install torch-geometric

# GNN:同时预测ADHD和性别
# 每个样本生成一个图对象
from torch_geometric.data import Data
import torch

def create_graph_from_connectome(row, node_num=36):
    matrix = row.values.reshape((node_num, node_num))
    edge_index = torch.tensor(np.array(np.nonzero(matrix)), dtype=torch.long)
    edge_attr = torch.tensor(matrix[np.nonzero(matrix)], dtype=torch.float32).flatten()
    x = torch.eye(node_num)  # 使用单位矩阵作为初始节点特征
    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)

import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool

class GNNEncoder(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels):
        super().__init__()
        self.conv1 = GATConv(in_channels, hidden_channels, heads=4, concat=True)
        self.conv2 = GATConv(hidden_channels*4, hidden_channels)

    def forward(self, x, edge_index):
        x = F.elu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return x

"""encoder 输出的每个脑区表示送入 Transformer"""

from torch.nn import TransformerEncoder, TransformerEncoderLayer

class BrainTransformer(torch.nn.Module):
    def __init__(self, input_dim, nhead=4, dim_feedforward=256):
        super().__init__()
        encoder_layer = TransformerEncoderLayer(input_dim, nhead, dim_feedforward)
        self.transformer = TransformerEncoder(encoder_layer, num_layers=2)

    def forward(self, x):  # x shape: [batch, num_nodes, feature]
        return self.transformer(x)

"""加权损失函数"""

class MultiTaskModel(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        # Shared layers
        self.shared = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        # Task-specific layers
        self.adhd_head = nn.Linear(hidden_dim, 2)  # Binary classification
        self.gender_head = nn.Linear(hidden_dim, 2)  # Binary classification

    def forward(self, x):
        # Shared features
        shared_features = self.shared(x)

        # Task-specific predictions
        adhd_out = self.adhd_head(shared_features)
        gender_out = self.gender_head(shared_features)

        return adhd_out, gender_out

"""自定义加权损失函数"""

def custom_loss(ad_hd_pred, ad_hd_true, gender_pred, gender_true, adhd_weights=None):
    loss1 = F.cross_entropy(ad_hd_pred, ad_hd_true, weight=adhd_weights)
    loss2 = F.cross_entropy(gender_pred, gender_true)
    return 0.7 * loss1 + 0.3 * loss2

# 安装 PyTorch Geometric 所需依赖
!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
!pip install torch-geometric

# GNN Encoder
class GNNEncoder(nn.Module):
    def __init__(self, in_channels, hidden_channels):
        super().__init__()
        self.conv1 = GATConv(in_channels, hidden_channels, heads=4, concat=True)
        self.conv2 = GATConv(hidden_channels*4, hidden_channels)

    def forward(self, x, edge_index):
        x = F.elu(self.conv1(x, edge_index))
        x = self.conv2(x, edge_index)
        return x

# Multi-task Prediction Head
class MultiTaskModel(nn.Module):
    def __init__(self, encoder, transformer, feature_dim):
        super().__init__()
        self.encoder = encoder
        self.transformer = transformer
        self.ad_hd_head = nn.Linear(feature_dim, 2)
        self.gender_head = nn.Linear(feature_dim, 2)

    def forward(self, data):
        # 从data中获取所需的属性
        x, edge_index, batch = data.x, data.edge_index, data.batch

        # 通过encoder
        x = self.encoder(x, edge_index)

        # 全局池化
        x = global_mean_pool(x, batch)

        # 通过transformer
        x = self.transformer(x.unsqueeze(1)).squeeze(1)

        # 任务特定的预测
        adhd_out = self.ad_hd_head(x)
        gender_out = self.gender_head(x)

        return adhd_out, gender_out

# 1. 首先创建 GNNEncoder
encoder = GNNEncoder(
    in_channels=36,  # 输入特征维度
    hidden_channels=64  # 隐藏层维度
)

# 2. 创建 Transformer
transformer = BrainTransformer(
    input_dim=64,  # 要与 GNNEncoder 的 hidden_channels 匹配
    nhead=4,
    dim_feedforward=256
)

# 3. 然后将 encoder 传入 MultiTaskModel
model = MultiTaskModel(
    encoder=encoder,
    transformer=transformer,
    feature_dim=64  # 要与 encoder 的 hidden_channels 匹配
)

# 4. 将整个模型移到指定设备
model = model.to(device)

# Custom Loss Function
def custom_loss(ad_hd_pred, ad_hd_true, gender_pred, gender_true, adhd_weights=None):
    loss1 = F.cross_entropy(ad_hd_pred, ad_hd_true, weight=adhd_weights)
    loss2 = F.cross_entropy(gender_pred, gender_true)
    return 0.7 * loss1 + 0.3 * loss2

"""# Training Loop"""

def train(model, train_loader, optimizer, device, adhd_weight):
    model.train()
    total_loss = 0
    num_batches = len(train_loader)  # 获取批次总数

    for batch_idx, batch in enumerate(train_loader):
        try:
            # 将batch移到指定设备
            batch = batch.to(device)

            # 清除梯度
            optimizer.zero_grad()

            # 前向传播
            adhd_logits, gender_logits = model(batch)

            # 计算损失
            adhd_loss = F.cross_entropy(adhd_logits, batch.y_adhd)
            gender_loss = F.cross_entropy(gender_logits, batch.y_gender)

            # 使用权重组合损失
            loss = adhd_weight[batch.y_gender] * adhd_loss + gender_loss

            # 反向传播
            loss.backward()

            # 更新参数
            optimizer.step()

            # 累加损失
            total_loss += loss.item()

            # 打印每个批次的进度
            if (batch_idx + 1) % 10 == 0:  # 每10个批次打印一次
                print(f'Batch [{batch_idx + 1}/{num_batches}], '
                      f'Loss: {loss.item():.4f}, '
                      f'ADHD Loss: {adhd_loss.item():.4f}, '
                      f'Gender Loss: {gender_loss.item():.4f}')

        except Exception as e:
            print(f"Error in batch {batch_idx}: {str(e)}")
            print(f"Batch info:")
            if hasattr(batch, 'x'):
                print(f"- x shape: {batch.x.shape}")
            if hasattr(batch, 'edge_index'):
                print(f"- edge_index shape: {batch.edge_index.shape}")
            if hasattr(batch, 'batch'):
                print(f"- batch shape: {batch.batch.shape}")
            if hasattr(batch, 'y_adhd'):
                print(f"- y_adhd shape: {batch.y_adhd.shape}")
            if hasattr(batch, 'y_gender'):
                print(f"- y_gender shape: {batch.y_gender.shape}")
            continue

    # 计算平均损失
    avg_loss = total_loss / num_batches
    return avg_loss

# 主训练循环
def main():
    # 设置设备
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # 创建数据加载器
    train_loader, valid_loader = create_data_loaders()  # 你需要实现这个函数

    # 创建模型
    model = MultiTaskModel(
        encoder=GNNEncoder(in_channels=36, hidden_channels=64),
        transformer=BrainTransformer(input_dim=64),
        feature_dim=64
    ).to(device)

    # 创建优化器
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # 设置ADHD权重
    adhd_weight = torch.tensor([1.0, 2.5], device=device)

    # 训练循环
    num_epochs = 20
    best_val_metrics = None

    for epoch in range(1, num_epochs + 1):
        # 训练一个epoch
        train_loss = train(model, train_loader, optimizer, device, adhd_weight)

        # 评估
        val_metrics = evaluate(model, valid_loader, device)

        # 打印结果
        print(f"Epoch {epoch:03d}, Loss: {train_loss:.4f}, "
              f"ADHD Acc: {val_metrics['adhd_acc']:.3f}, "
              f"Gender Acc: {val_metrics['gender_acc']:.3f}")

        # 保存最佳模型
        if best_val_metrics is None or val_metrics['val_loss'] < best_val_metrics['val_loss']:
            best_val_metrics = val_metrics
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_metrics': val_metrics,
            }, 'best_model.pt')

        print("-" * 50)

def create_data_loaders():
    # 加载数据
    connectome_df, metadata_df = load_data()

    # 创建图数据集
    graphs = create_graph_dataset(connectome_df, metadata_df)

    # 划分训练集和验证集
    num_train = int(0.8 * len(graphs))
    train_graphs = graphs[:num_train]
    valid_graphs = graphs[num_train:]

    # 创建数据加载器
    train_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)
    valid_loader = DataLoader(valid_graphs, batch_size=16, shuffle=False)

    return train_loader, valid_loader

if __name__ == "__main__":
    main()

"""# Evaluation Loop"""

def evaluate(model, dataloader, device):
    model.eval()
    total_adhd_correct = 0
    total_gender_correct = 0
    total_samples = 0
    total_loss = 0

    with torch.no_grad():
        for batch in dataloader:
            try:
                # 将整个batch移动到设备上
                batch = batch.to(device)

                # 前向传播 - 只传入batch
                out_adhd, out_gender = model(batch)  # 注意这里只传入batch

                # 计算准确率
                _, adhd_pred = out_adhd.max(dim=1)
                _, gender_pred = out_gender.max(dim=1)

                total_adhd_correct += (adhd_pred == batch.y_adhd).sum().item()
                total_gender_correct += (gender_pred == batch.y_gender).sum().item()
                total_samples += batch.num_graphs

                # 计算损失
                loss = multitask_loss_fn(
                    out_adhd, batch.y_adhd,
                    out_gender, batch.y_gender,
                    adhd_weight=0.7
                )
                total_loss += loss.item()

            except Exception as e:
                print(f"Error during evaluation: {str(e)}")
                print(f"Batch info:")
                print(f"- x shape: {batch.x.shape if hasattr(batch, 'x') else 'No x'}")
                print(f"- edge_index shape: {batch.edge_index.shape if hasattr(batch, 'edge_index') else 'No edge_index'}")
                print(f"- batch shape: {batch.batch.shape if hasattr(batch, 'batch') else 'No batch'}")
                print(f"- y_adhd shape: {batch.y_adhd.shape if hasattr(batch, 'y_adhd') else 'No y_adhd'}")
                print(f"- y_gender shape: {batch.y_gender.shape if hasattr(batch, 'y_gender') else 'No y_gender'}")
                continue

    if total_samples == 0:
        return {
            'adhd_acc': 0.0,
            'gender_acc': 0.0,
            'val_loss': float('inf')
        }

    return {
        'adhd_acc': total_adhd_correct / total_samples,
        'gender_acc': total_gender_correct / total_samples,
        'val_loss': total_loss / len(dataloader)
    }

"""损失函数"""

def multitask_loss_fn(out_adhd, y_adhd, out_gender, y_gender, adhd_weight=0.7):
    # 将 adhd_weight 转换为 tensor
    adhd_weight_tensor = torch.tensor(adhd_weight).to(out_adhd.device)

    # ADHD 分类损失
    adhd_loss = F.cross_entropy(out_adhd, y_adhd)

    # 性别分类损失
    gender_loss = F.cross_entropy(out_gender, y_gender)

    # 总损失
    total_loss = adhd_weight_tensor * adhd_loss + (1 - adhd_weight_tensor) * gender_loss

    return total_loss

from sklearn.metrics import accuracy_score, f1_score

def train(model, loader, optimizer, device, adhd_weight=None):
    model.train()
    total_loss = 0
    for batch in loader:
        batch = batch.to(device)
        optimizer.zero_grad()
        out_adhd, out_gender = model(batch.x, batch.edge_index, batch.batch)
        loss = multitask_loss_fn(out_adhd, batch.y_adhd, out_gender, batch.y_gender, adhd_weight)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def evaluate(model, loader, device):
    model.eval()
    preds_adhd, preds_gender = [], []
    trues_adhd, trues_gender = [], []

    with torch.no_grad():
        for batch in loader:
            batch = batch.to(device)
            out_adhd, out_gender = model(batch.x, batch.edge_index, batch.batch)
            preds_adhd += out_adhd.argmax(dim=1).cpu().tolist()
            preds_gender += out_gender.argmax(dim=1).cpu().tolist()
            trues_adhd += batch.y_adhd.cpu().tolist()
            trues_gender += batch.y_gender.cpu().tolist()

    return {
        'adhd_acc': accuracy_score(trues_adhd, preds_adhd),
        'adhd_f1': f1_score(trues_adhd, preds_adhd),
        'gender_acc': accuracy_score(trues_gender, preds_gender),
        'gender_f1': f1_score(trues_gender, preds_gender),
    }

def create_data_batch(connectome_data, metadata):
    graphs = []
    for idx, row in connectome_data.iterrows():
        # 创建图数据
        data = Data(
            x=torch.tensor(row.values[1:].reshape(36, 36).astype(np.float32)),  # 特征矩阵
            edge_index=torch.tensor(np.array(np.nonzero(row.values[1:].reshape(36, 36))), dtype=torch.long),  # 边索引
            y_adhd=torch.tensor(metadata.loc[metadata['participant_id'] == row['participant_id'], 'ADHD_Outcome'].values[0], dtype=torch.long),  # ADHD标签
            y_gender=torch.tensor(metadata.loc[metadata['participant_id'] == row['participant_id'], 'Sex_F'].values[0], dtype=torch.long)  # 性别标签
        )
        graphs.append(data)
    return graphs

# 创建数据加载器
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

"""开始训练"""

print(solutions_df.head())

solutions_df.to_csv("submission.csv", index=False)

from google.colab import files
files.download("submission.csv")

connectome_df = pd.read_csv("TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv")

def restore_full_symmetric(flat_lower):
    if len(flat_lower) == 19899:
        flat_lower = np.concatenate([flat_lower, [0]])  # 更高效
    N = 199
    mat = np.zeros((N, N))
    indices = np.tril_indices(N, k=0)
    mat[indices] = flat_lower
    mat = mat + mat.T - np.diag(mat.diagonal())
    return mat

import numpy as np

adhd_label = solutions_df["ADHD_Outcome"].values
sex_label = solutions_df["Sex_F"].values

graph_list = []

for i in range(100):
    flat_conn = connectome_df.iloc[i, 2:].values
    if len(flat_conn) == 19899:
        flat_conn = np.append(flat_conn, 0)

    conn_vec = restore_full_symmetric(flat_conn)
    edge_index = torch.tensor(np.array(np.nonzero(conn_vec)), dtype=torch.long)
    edge_attr = torch.tensor(conn_vec[np.nonzero(conn_vec)], dtype=torch.float)

    num_nodes = conn_vec.shape[0]  # 通常是 199
    x = torch.eye(36).repeat(num_nodes, 1)  # 每个节点36维单位特征

    y = torch.tensor([adhd_label[i], sex_label[i]], dtype=torch.long)

    graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
    graph_list.append(graph)

from torch_geometric.data import Data
from torch_geometric.loader import DataLoader

graph_list = []
for i in range(100):  # 示例，使用前100个样本
    flat_conn = connectome_df.iloc[i, 2:].values
    conn_vec = restore_full_symmetric(flat_conn)
    edge_index = torch.tensor(np.array(np.nonzero(conn_vec)), dtype=torch.long)
    edge_attr = torch.tensor(conn_vec[np.nonzero(conn_vec)], dtype=torch.float)
    num_nodes = conn_vec.shape[0]
    x = torch.randn(num_nodes, 36)
    y = torch.tensor([adhd_label[i], sex_label[i]], dtype=torch.long)

    graph = Data(
    x=x,
    edge_index=edge_index,
    edge_attr=edge_attr,
    y_adhd=torch.tensor(adhd_label[i], dtype=torch.long),
    y_gender=torch.tensor(sex_label[i], dtype=torch.long)
)
    graph_list.append(graph)

# 用 PyG 的 DataLoader 自动处理多图拼接
dataloader = DataLoader(graph_list, batch_size=32, shuffle=True)

train_loader = dataloader
valid_loader = dataloader

from torch_geometric.loader import DataLoader
from torch_geometric.data import Batch

dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
dataloader = DataLoader(graph_list, batch_size=32, shuffle=True)
model = MultiTaskModel(
    encoder=GNNEncoder(36, 64),          # ← 输入维度为 36
    transformer=BrainTransformer(64),
    feature_dim=64
)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
adhd_weight = torch.tensor([1.0, 3.0], device=dev)

"""Training loop"""

# Training loop
num_epochs = 100
best_val_metrics = None

for epoch in range(num_epochs):
    model.train()
    total_loss = 0

    for batch in train_loader:
        try:
            # 将batch移到设备上
            batch = batch.to(device)

            # 优化器梯度清零
            optimizer.zero_grad()

            # 前向传播 - 只传入batch
            out_adhd, out_gender = model(batch)

            # 计算损失
            loss = multitask_loss_fn(
                out_adhd, batch.y_adhd,
                out_gender, batch.y_gender,
                adhd_weight=0.7
            )

            # 反向传播
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        except Exception as e:
            print(f"Error during training: {str(e)}")
            continue

    # 评估
    val_metrics = evaluate(model, valid_loader, device)

    # 打印结果
    print(f"Epoch {epoch+1}/{num_epochs}")
    print(f"Train Loss: {total_loss/len(train_loader):.4f}")
    print(f"Val ADHD Acc: {val_metrics['adhd_acc']:.4f}")
    print(f"Val Gender Acc: {val_metrics['gender_acc']:.4f}")
    print(f"Val Loss: {val_metrics['val_loss']:.4f}")

    # 保存最佳模型
    if best_val_metrics is None or val_metrics['val_loss'] < best_val_metrics['val_loss']:
        best_val_metrics = val_metrics
        torch.save(model.state_dict(), 'best_model.pt')

    print("-" * 50)

"""验证函数"""

from sklearn.metrics import accuracy_score, f1_score

def evaluate(model, dataloader, device):
    model.eval()
    total_adhd_correct = 0
    total_gender_correct = 0
    total_samples = 0
    total_loss = 0

    # 用于计算 F1 分数
    adhd_preds = []
    adhd_true = []
    gender_preds = []
    gender_true = []

    with torch.no_grad():
        for batch in dataloader:
            try:
                # 将整个batch移动到设备上
                batch = batch.to(device)

                # 前向传播 - 只传入整个batch对象
                adhd_logits, gender_logits = model(batch)

                # 获取预测结果
                adhd_pred = adhd_logits.argmax(dim=1)
                gender_pred = gender_logits.argmax(dim=1)

                # 收集预测和真实标签用于计算 F1
                adhd_preds.extend(adhd_pred.cpu().numpy())
                adhd_true.extend(batch.y_adhd.cpu().numpy())
                gender_preds.extend(gender_pred.cpu().numpy())
                gender_true.extend(batch.y_gender.cpu().numpy())

                # 计算准确率
                total_adhd_correct += (adhd_pred == batch.y_adhd).sum().item()
                total_gender_correct += (gender_pred == batch.y_gender).sum().item()
                total_samples += batch.num_graphs

                # 计算损失
                loss = multitask_loss_fn(
                    adhd_logits, batch.y_adhd,
                    gender_logits, batch.y_gender,
                    adhd_weight=0.7
                )
                total_loss += loss.item()

            except Exception as e:
                print(f"Error during evaluation: {str(e)}")
                print(f"Batch info:")
                if hasattr(batch, 'x'):
                    print(f"- x shape: {batch.x.shape}")
                if hasattr(batch, 'edge_index'):
                    print(f"- edge_index shape: {batch.edge_index.shape}")
                if hasattr(batch, 'batch'):
                    print(f"- batch shape: {batch.batch.shape}")
                if hasattr(batch, 'y_adhd'):
                    print(f"- y_adhd shape: {batch.y_adhd.shape}")
                if hasattr(batch, 'y_gender'):
                    print(f"- y_gender shape: {batch.y_gender.shape}")
                continue

    # 计算平均指标
    metrics = {}
    if total_samples > 0:
        # 计算准确率
        metrics['adhd_acc'] = total_adhd_correct / total_samples
        metrics['gender_acc'] = total_gender_correct / total_samples
        metrics['val_loss'] = total_loss / len(dataloader)

        # 计算 F1 分数
        from sklearn.metrics import f1_score
        metrics['adhd_f1'] = f1_score(adhd_true, adhd_preds, average='binary')
        metrics['gender_f1'] = f1_score(gender_true, gender_preds, average='binary')
    else:
        metrics = {
            'adhd_acc': 0.0,
            'gender_acc': 0.0,
            'val_loss': float('inf'),
            'adhd_f1': 0.0,
            'gender_f1': 0.0
        }

    return metrics

# 评估模型
model.eval()  # 设置为评估模式
val_metrics = evaluate(model, valid_loader, device)

print(f"ADHD F1: {val_metrics['adhd_f1']:.3f}, Gender F1: {val_metrics['gender_f1']:.3f}")
print(f"ADHD Acc: {val_metrics['adhd_acc']:.3f}, Gender Acc: {val_metrics['gender_acc']:.3f}")
print(f"Val Loss: {val_metrics['val_loss']:.3f}")

"""模型训练"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
feature_dim = 36

model = MultiTaskModel(
    encoder=GNNEncoder(in_channels=feature_dim, hidden_channels=64),
    transformer=BrainTransformer(input_dim=64),
    feature_dim=64
).to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
adhd_weight = torch.tensor([1.0, 2.5], device=device)  # 给女性ADHD更高权重

for epoch in range(1, 21):
    loss = train(model, train_loader, optimizer, device, adhd_weight)
    metrics = evaluate(model, valid_loader, device)
    print(f"Epoch {epoch:02d}, Loss: {loss:.4f}, ADHD Acc: {metrics['adhd_acc']:.3f}, Gender Acc: {metrics['gender_acc']:.3f}")

from torch_geometric.utils import dense_to_sparse

def convert_fmri_to_graph(fc_path, demo_path):
    # 1. Load connectome matrix
    fc_matrices = np.load(fc_path)  # Shape: [N, R, R]
    N, R = fc_matrices.shape[0], fc_matrices.shape[1]

    # 2. Load labels
    demo = pd.read_csv(demo_path)

    assert len(demo) == N, "Mismatch between connectome and demographic data."

    # 3. Static edge_index: assume fully connected graph
    template = np.ones((R, R)) - np.eye(R)
    edge_index, _ = dense_to_sparse(torch.tensor(template))

    # 4. Convert each subject into a Data object
    data_list = []
    for i in range(N):
        fc = fc_matrices[i]  # [R, R]

        # Option 1: use edge weights from upper triangle only
        edge_weight = fc[template.astype(bool)]  # Flattened weights
        edge_weight = torch.tensor(edge_weight, dtype=torch.float)

        # Node features: optional (use all 1s or node degree or demographic info per node)
        x = torch.ones((R, 1), dtype=torch.float)  # [R, 1] node feature

        # Labels
        adhd_label = torch.tensor(int(demo.loc[i, 'adhd']), dtype=torch.long)
        gender_label = torch.tensor(int(demo.loc[i, 'gender']), dtype=torch.long)

        data = Data(
            x=x,
            edge_index=edge_index,
            edge_attr=edge_weight,
            y_adhd=adhd_label,
            y_gender=gender_label
        )
        data_list.append(data)

    return data_list

import numpy as np
import pandas as pd

N = 100    # 样本数量
R = 36     # 脑区数量
fc_matrices = np.random.rand(N, R, R)

# 对角线置0，或对称化
for i in range(N):
    mat = fc_matrices[i]
    mat = (mat + mat.T) / 2
    np.fill_diagonal(mat, 0)
    fc_matrices[i] = mat

np.save("fc_matrices.npy", fc_matrices)

demo_df = pd.DataFrame({
    'adhd': np.random.randint(0, 2, size=N),
    'gender': np.random.randint(0, 2, size=N)
})
demo_df.to_csv("demo.csv", index=False)

data_list = convert_fmri_to_graph('fc_matrices.npy', 'demo.csv')

# 划分训练集
from sklearn.model_selection import train_test_split
from torch_geometric.loader import DataLoader

train_set, val_set = train_test_split(data_list, test_size=0.2, random_state=42)
train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
val_loader = DataLoader(val_set, batch_size=32)

# 连接矩阵和元数据
connectomes = np.load('fc_matrices.npy')  # shape: [N, R, R]，N个样本，R个脑区
metadata = pd.read_csv('demo.csv')  # 包含 y_gender, y_adhd

# 构造图数据列表
graph_list = []
for i in range(len(connectomes)):
    matrix = connectomes[i]
    edge_index = torch.tensor(np.array(matrix > 0).nonzero(), dtype=torch.long)
    edge_weight = torch.tensor(matrix[matrix > 0], dtype=torch.float)
    x = torch.tensor(matrix, dtype=torch.float).mean(dim=1, keepdim=True)  # 节点特征

    y_gender = torch.tensor(metadata.iloc[i]['gender'], dtype=torch.long)
    y_adhd = torch.tensor(metadata.iloc[i]['adhd'], dtype=torch.long)

    graph = Data(x=x, edge_index=edge_index, edge_attr=edge_weight,
                 y_gender=y_gender, y_adhd=y_adhd)
    graph_list.append(graph)

import matplotlib.pyplot as plt

num_epochs = 20
train_loss_list = []
adhd_f1_list = []
gender_f1_list = []

import torch
from torch_geometric.data import Data, DataLoader
import numpy as np
import pandas as pd

# 1. 首先加载数据
def load_data():
    # 加载数据
    categorical_df = pd.read_excel("TRAIN_CATEGORICAL_METADATA_new.xlsx")
    quantitative_df = pd.read_excel("TRAIN_QUANTITATIVE_METADATA_new.xlsx")
    solutions_df = pd.read_excel("TRAINING_SOLUTIONS.xlsx")
    connectome_df = pd.read_csv("TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv")

    # 合并元数据
    merged_df = solutions_df.merge(categorical_df, on="participant_id", how="left")
    merged_df = merged_df.merge(quantitative_df, on="participant_id", how="left")

    return connectome_df, merged_df

# 2. 创建图数据
def create_graph_dataset(connectome_df, metadata_df):
    graphs = []
    skipped = 0
    for idx, row in connectome_df.iterrows():
        try:
            participant_id = row['participant_id']
            matrix_flat = row.values[1:]
            if len(matrix_flat) != 36 * 36:
                raise ValueError(f"Invalid matrix length: {len(matrix_flat)}")
            matrix = matrix_flat.reshape(36, 36).astype(np.float32)

            data = Data(
                x=torch.tensor(matrix, dtype=torch.float),
                edge_index=torch.tensor(np.array(np.nonzero(matrix)), dtype=torch.long),
                edge_attr=torch.tensor(matrix[np.nonzero(matrix)], dtype=torch.float).reshape(-1, 1)
            )

            participant_data = metadata_df[metadata_df['participant_id'] == participant_id]
            if participant_data.empty:
                raise ValueError("Participant metadata missing.")
            participant_data = participant_data.iloc[0]

            data.y_adhd = torch.tensor(participant_data['ADHD_Outcome'], dtype=torch.long)
            data.y_gender = torch.tensor(participant_data['Sex_F'], dtype=torch.long)

            graphs.append(data)

        except Exception as e:
            print(f"Error processing participant {participant_id}: {str(e)}")
            skipped += 1
            continue

    print(f"[INFO] Created {len(graphs)} graphs. Skipped {skipped}.")
    return graphs


# 3. 主要处理流程
def main():
    # 设置设备
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # 加载数据
    print("Loading data...")
    connectome_df, metadata_df = load_data()

    # 创建图数据集
    print("Creating graph dataset...")
    graphs = create_graph_dataset(connectome_df, metadata_df)
    print(f"Created {len(graphs)} graphs")

    # 创建数据加载器
    loader = DataLoader(graphs, batch_size=16, shuffle=True)

    # 打印第一个图的信息以验证
    print("\nFirst graph info:")
    first_graph = graphs[0]
    print(f"- Number of nodes: {first_graph.x.size(0)}")
    print(f"- Number of edges: {first_graph.edge_index.size(1)}")
    print(f"- Node features shape: {first_graph.x.shape}")
    print(f"- Edge features shape: {first_graph.edge_attr.shape}")
    print(f"- ADHD label: {first_graph.y_adhd}")
    print(f"- Gender label: {first_graph.y_gender}")

    return loader, graphs

# 4. 运行主程序
if __name__ == "__main__":
    loader, graphs = main()

# 创建 GIN 模型
class GIN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = GINConv(
            Sequential(
                Linear(in_channels, hidden_channels),
                ReLU(),
                Linear(hidden_channels, hidden_channels)
            )
        )
        self.lin1 = Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch):
        x = self.conv1(x, edge_index)
        x = global_add_pool(x, batch)
        x = self.lin1(x)
        return x

# 创建模型实例
model = GIN(
    in_channels=36,  # 输入特征维度
    hidden_channels=64,  # 隐藏层维度
    out_channels=2  # 输出类别数
).to(device)

# 创建优化器
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# 使用数据加载器进行训练
for epoch in range(100):
    model.train()
    total_loss = 0
    for batch in loader:
        batch = batch.to(device)
        optimizer.zero_grad()

        # 前向传播
        out = model(batch.x, batch.edge_index, batch.batch)

        # 计算损失
        loss = F.cross_entropy(out, batch.y_adhd)  # 或 batch.y_gender 取决于任务

        # 反向传播
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f'Epoch {epoch:03d}, Loss: {total_loss/len(loader):.4f}')

# 假设 graphs 列表已经构建好
loader = DataLoader(graphs, batch_size=16, shuffle=True)

class GIN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        nn = Sequential(Linear(in_channels, hidden_channels), ReLU(), Linear(hidden_channels, hidden_channels))
        self.conv1 = GINConv(nn)
        self.lin1 = Linear(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch):
        x = self.conv1(x, edge_index)
        x = global_add_pool(x, batch)
        x = self.lin1(x)
        return x

# 初始化模型
model = GIN(in_channels=36, hidden_channels=64, out_channels=2)  # 二分类任务（ADHD）
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.CrossEntropyLoss()

# 训练
for epoch in range(1, num_epochs + 1):
    loss = train(model, train_loader, optimizer, device, adhd_weight)
    metrics = evaluate(model, valid_loader, device)

    train_loss_list.append(loss)
    adhd_f1_list.append(metrics['adhd_f1'])
    gender_f1_list.append(metrics['gender_f1'])

    print(f"Epoch {epoch:02d}, Loss: {loss:.4f}, "
          f"ADHD F1: {metrics['adhd_f1']:.3f}, "
          f"Gender F1: {metrics['gender_f1']:.3f}")

"""训练曲线图"""

plt.figure(figsize=(12, 4))

# Loss 曲线
plt.subplot(1, 3, 1)
plt.plot(train_loss_list, label='Train Loss', marker='o')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)

# ADHD F1 曲线
plt.subplot(1, 3, 2)
plt.plot(adhd_f1_list, label='ADHD F1', marker='o', color='orange')
plt.title('ADHD F1 Score')
plt.xlabel('Epoch')
plt.ylabel('F1 Score')
plt.grid(True)

# Gender F1 曲线
plt.subplot(1, 3, 3)
plt.plot(gender_f1_list, label='Gender F1', marker='o', color='green')
plt.title('Gender F1 Score')
plt.xlabel('Epoch')
plt.ylabel('F1 Score')
plt.grid(True)

plt.tight_layout()
plt.show()

"""保存每轮结果到 CSV"""

import pandas as pd

log_df = pd.DataFrame({
    'epoch': list(range(1, num_epochs + 1)),
    'loss': train_loss_list,
    'adhd_f1': adhd_f1_list,
    'gender_f1': gender_f1_list
})

log_df.to_csv('training_metrics.csv', index=False)

"""划分 test 数据"""

from sklearn.model_selection import train_test_split
train_val_set, test_set = train_test_split(data_list, test_size=0.1, random_state=42)
train_set, val_set = train_test_split(train_val_set, test_size=0.2, random_state=42)

"""加载 test 数据"""

test_loader = DataLoader(test_set, batch_size=32, shuffle=False)

"""test data 上评估"""

test_metrics = evaluate(model, test_loader, device)
print("Test Results:", test_metrics)